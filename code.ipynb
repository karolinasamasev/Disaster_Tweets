{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vajalikud impordid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "import tensorflow as tf\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Andmete sisse lugemine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608</th>\n",
       "      <td>10869</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Two giant cranes holding a bridge collapse int...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7609</th>\n",
       "      <td>10870</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@aria_ahrary @TheTawniest The out of control w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7610</th>\n",
       "      <td>10871</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7611</th>\n",
       "      <td>10872</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Police investigating after an e-bike collided ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7612</th>\n",
       "      <td>10873</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Latest: More Homes Razed by Northern Calif...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7613 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id keyword location  \\\n",
       "0         1     NaN      NaN   \n",
       "1         4     NaN      NaN   \n",
       "2         5     NaN      NaN   \n",
       "3         6     NaN      NaN   \n",
       "4         7     NaN      NaN   \n",
       "...     ...     ...      ...   \n",
       "7608  10869     NaN      NaN   \n",
       "7609  10870     NaN      NaN   \n",
       "7610  10871     NaN      NaN   \n",
       "7611  10872     NaN      NaN   \n",
       "7612  10873     NaN      NaN   \n",
       "\n",
       "                                                   text  target  \n",
       "0     Our Deeds are the Reason of this #earthquake M...       1  \n",
       "1                Forest fire near La Ronge Sask. Canada       1  \n",
       "2     All residents asked to 'shelter in place' are ...       1  \n",
       "3     13,000 people receive #wildfires evacuation or...       1  \n",
       "4     Just got sent this photo from Ruby #Alaska as ...       1  \n",
       "...                                                 ...     ...  \n",
       "7608  Two giant cranes holding a bridge collapse int...       1  \n",
       "7609  @aria_ahrary @TheTawniest The out of control w...       1  \n",
       "7610  M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...       1  \n",
       "7611  Police investigating after an e-bike collided ...       1  \n",
       "7612  The Latest: More Homes Razed by Northern Calif...       1  \n",
       "\n",
       "[7613 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3258</th>\n",
       "      <td>10861</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EARTHQUAKE SAFETY LOS ANGELES ÛÒ SAFETY FASTE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3259</th>\n",
       "      <td>10865</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Storm in RI worse than last hurricane. My city...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3260</th>\n",
       "      <td>10868</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Green Line derailment in Chicago http://t.co/U...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3261</th>\n",
       "      <td>10874</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MEG issues Hazardous Weather Outlook (HWO) htt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>10875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#CityofCalgary has activated its Municipal Eme...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3263 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id keyword location  \\\n",
       "0         0     NaN      NaN   \n",
       "1         2     NaN      NaN   \n",
       "2         3     NaN      NaN   \n",
       "3         9     NaN      NaN   \n",
       "4        11     NaN      NaN   \n",
       "...     ...     ...      ...   \n",
       "3258  10861     NaN      NaN   \n",
       "3259  10865     NaN      NaN   \n",
       "3260  10868     NaN      NaN   \n",
       "3261  10874     NaN      NaN   \n",
       "3262  10875     NaN      NaN   \n",
       "\n",
       "                                                   text  \n",
       "0                    Just happened a terrible car crash  \n",
       "1     Heard about #earthquake is different cities, s...  \n",
       "2     there is a forest fire at spot pond, geese are...  \n",
       "3              Apocalypse lighting. #Spokane #wildfires  \n",
       "4         Typhoon Soudelor kills 28 in China and Taiwan  \n",
       "...                                                 ...  \n",
       "3258  EARTHQUAKE SAFETY LOS ANGELES ÛÒ SAFETY FASTE...  \n",
       "3259  Storm in RI worse than last hurricane. My city...  \n",
       "3260  Green Line derailment in Chicago http://t.co/U...  \n",
       "3261  MEG issues Hazardous Weather Outlook (HWO) htt...  \n",
       "3262  #CityofCalgary has activated its Municipal Eme...  \n",
       "\n",
       "[3263 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('test.csv')\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id 0\n",
      "keyword 26\n",
      "location 1105\n",
      "text 0\n"
     ]
    }
   ],
   "source": [
    "'''Loeme kokku NaN väärtusi igas veerus'''\n",
    "\n",
    "for col in test.columns:\n",
    "    print(col, test[col].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7613 entries, 0 to 7612\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        7613 non-null   int64 \n",
      " 1   keyword   7552 non-null   object\n",
      " 2   location  5080 non-null   object\n",
      " 3   text      7613 non-null   object\n",
      " 4   target    7613 non-null   int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 297.5+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eeltöötlus"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eeltöötluse käigus puhastasin andmestiku, suuremas osas just \"text\" veergu. Kasutasin selle jaoks regexit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608</th>\n",
       "      <td>Two giant cranes holding a bridge collapse int...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7609</th>\n",
       "      <td>@aria_ahrary @TheTawniest The out of control w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7610</th>\n",
       "      <td>M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7611</th>\n",
       "      <td>Police investigating after an e-bike collided ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7612</th>\n",
       "      <td>The Latest: More Homes Razed by Northern Calif...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7613 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  target\n",
       "0     Our Deeds are the Reason of this #earthquake M...       1\n",
       "1                Forest fire near La Ronge Sask. Canada       1\n",
       "2     All residents asked to 'shelter in place' are ...       1\n",
       "3     13,000 people receive #wildfires evacuation or...       1\n",
       "4     Just got sent this photo from Ruby #Alaska as ...       1\n",
       "...                                                 ...     ...\n",
       "7608  Two giant cranes holding a bridge collapse int...       1\n",
       "7609  @aria_ahrary @TheTawniest The out of control w...       1\n",
       "7610  M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...       1\n",
       "7611  Police investigating after an e-bike collided ...       1\n",
       "7612  The Latest: More Homes Razed by Northern Calif...       1\n",
       "\n",
       "[7613 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Jätame alles ainult text-nimelise veeru, kuna ülejäänud veerud on minu arvates ennustamiseks ebavajalikud'''\n",
    "\n",
    "train = train.drop(['id', 'keyword', 'location'], axis=1) \n",
    "test = test.drop(['keyword', 'location'], axis=1)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Defineerime funktsioonid teksti töötlemiseks ja puhastamiseks'''\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    # ['!','\"','$','%','&',\"'\",'(',')','*',\n",
    "    # '+',',','-','.','/',':',';','<','=',\n",
    "    # '>','?','@','[','\\\\',']','^','_','`',\n",
    "    # '{','|','}','~']\n",
    "    # kustutab tekstist ülaltoodud märgid\n",
    "    punctuations = list(string.punctuation)\n",
    "    table = str.maketrans('', '', ''.join(punctuations))\n",
    "    return text.translate(table)\n",
    "\n",
    "def remove_tag(text): \n",
    "    # kustutab @ märgi\n",
    "    tag = re.compile(r'@\\S+')\n",
    "    return tag.sub(r'',text)\n",
    "\n",
    "def remove_URL(text):\n",
    "    # kustutab kõik URL\n",
    "    url = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return re.sub(url,'',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\karol\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "'''nltk kustutab nn stopp-sõnad (näiteks \"the\" inglise sõnastikus)'''\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    return \" \".join([word for word in str(text).split() if word not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Rakendame üleval defineeritud funktsioonid'''\n",
    "\n",
    "train['cleaned'] = train['text'].apply(lambda x:remove_punctuation(x)).apply(lambda x:remove_tag(x)).apply(lambda x:remove_URL(x)).apply(lambda x: x.lower()).apply(lambda x: word_tokenize(x)).apply(lambda x:remove_stopwords(x))\n",
    "test['cleaned'] = test['text'].apply(lambda x:remove_punctuation(x)).apply(lambda x:remove_tag(x)).apply(lambda x:remove_URL(x)).apply(lambda x: x.lower()).apply(lambda x: word_tokenize(x)).apply(lambda x:remove_stopwords(x))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenizing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teksti närvivõrkudesse \"söötimiseks\" peame teksti tokeniseerima ja seejärel indekseerima või vektoriseerima. Siin me muudame iga teksti indeksite jadaks, kasutades tensorflow.keras.preprocessing.text.Tokenenizer, kus igal ainulaadsel sõnal on oma register."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 10000\n",
    "MAX_LENGTH = 20\n",
    "\n",
    "tokenizer = Tokenizer(num_words=VOCAB_SIZE, oov_token=\"<OOV>\", filters=\"\")\n",
    "tokenizer.fit_on_texts(train['text'])\n",
    "\n",
    "train_seq = tokenizer.texts_to_sequences(train['text'])\n",
    "train_padded = pad_sequences(train_seq, maxlen=MAX_LENGTH)\n",
    "\n",
    "test_seq = tokenizer.texts_to_sequences(test['text'])\n",
    "test_padded = pad_sequences(test_seq, maxlen=MAX_LENGTH)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mudel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Defineerime mudelit hüperparameetritega'''\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(VOCAB_SIZE, output_dim=16, input_length=MAX_LENGTH),\n",
    "        tf.keras.layers.Bidirectional(tf.keras.layers.GRU(16, dropout=0.4)),\n",
    "        tf.keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "])\n",
    "model.compile(optimizer= \"adam\", loss= \"binary_crossentropy\", metrics=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "238/238 [==============================] - 5s 8ms/step - loss: 0.6292 - accuracy: 0.6272\n",
      "Epoch 2/50\n",
      "238/238 [==============================] - 2s 8ms/step - loss: 0.4021 - accuracy: 0.8225\n",
      "Epoch 3/50\n",
      "238/238 [==============================] - 2s 8ms/step - loss: 0.3034 - accuracy: 0.8757\n",
      "Epoch 4/50\n",
      "238/238 [==============================] - 2s 8ms/step - loss: 0.2419 - accuracy: 0.9041\n",
      "Epoch 5/50\n",
      "238/238 [==============================] - 2s 8ms/step - loss: 0.2007 - accuracy: 0.9217\n",
      "Epoch 6/50\n",
      "238/238 [==============================] - 2s 8ms/step - loss: 0.1797 - accuracy: 0.9303\n",
      "Epoch 7/50\n",
      "238/238 [==============================] - 2s 8ms/step - loss: 0.1533 - accuracy: 0.9414\n",
      "Epoch 8/50\n",
      "238/238 [==============================] - 2s 8ms/step - loss: 0.1361 - accuracy: 0.9510\n",
      "Epoch 9/50\n",
      "238/238 [==============================] - 2s 8ms/step - loss: 0.1265 - accuracy: 0.9527\n",
      "Epoch 10/50\n",
      "238/238 [==============================] - 2s 8ms/step - loss: 0.1152 - accuracy: 0.9603\n",
      "Epoch 11/50\n",
      "238/238 [==============================] - 2s 8ms/step - loss: 0.1084 - accuracy: 0.9624\n",
      "Epoch 12/50\n",
      "238/238 [==============================] - 2s 8ms/step - loss: 0.1004 - accuracy: 0.9632\n",
      "Epoch 13/50\n",
      "238/238 [==============================] - 2s 8ms/step - loss: 0.0930 - accuracy: 0.9676\n",
      "Epoch 14/50\n",
      "238/238 [==============================] - 2s 8ms/step - loss: 0.0875 - accuracy: 0.9682\n",
      "Epoch 15/50\n",
      "238/238 [==============================] - 2s 8ms/step - loss: 0.0826 - accuracy: 0.9706\n",
      "Epoch 16/50\n",
      "238/238 [==============================] - 2s 8ms/step - loss: 0.0813 - accuracy: 0.9699\n",
      "Epoch 17/50\n",
      "238/238 [==============================] - 2s 8ms/step - loss: 0.0769 - accuracy: 0.9712\n",
      "Epoch 18/50\n",
      "238/238 [==============================] - 2s 9ms/step - loss: 0.0710 - accuracy: 0.9706\n",
      "Epoch 19/50\n",
      "238/238 [==============================] - 2s 9ms/step - loss: 0.0690 - accuracy: 0.9716\n",
      "Epoch 20/50\n",
      "238/238 [==============================] - 2s 9ms/step - loss: 0.0642 - accuracy: 0.9736\n",
      "Epoch 21/50\n",
      "238/238 [==============================] - 2s 9ms/step - loss: 0.0626 - accuracy: 0.9746\n",
      "Epoch 22/50\n",
      "238/238 [==============================] - 2s 9ms/step - loss: 0.0586 - accuracy: 0.9750\n",
      "Epoch 23/50\n",
      "238/238 [==============================] - 2s 9ms/step - loss: 0.0569 - accuracy: 0.9761\n",
      "Epoch 24/50\n",
      "238/238 [==============================] - 2s 9ms/step - loss: 0.0562 - accuracy: 0.9768\n",
      "Epoch 25/50\n",
      "238/238 [==============================] - 2s 10ms/step - loss: 0.0512 - accuracy: 0.9771\n",
      "Epoch 26/50\n",
      "238/238 [==============================] - 2s 9ms/step - loss: 0.0528 - accuracy: 0.9754\n",
      "Epoch 27/50\n",
      "238/238 [==============================] - 3s 13ms/step - loss: 0.0557 - accuracy: 0.9769\n",
      "Epoch 28/50\n",
      "238/238 [==============================] - 4s 15ms/step - loss: 0.0522 - accuracy: 0.9760\n",
      "Epoch 29/50\n",
      "238/238 [==============================] - 4s 17ms/step - loss: 0.0485 - accuracy: 0.9773\n",
      "Epoch 30/50\n",
      "238/238 [==============================] - 4s 18ms/step - loss: 0.0458 - accuracy: 0.9781\n",
      "Epoch 31/50\n",
      "238/238 [==============================] - 4s 17ms/step - loss: 0.0479 - accuracy: 0.9777\n",
      "Epoch 32/50\n",
      "238/238 [==============================] - 4s 16ms/step - loss: 0.0491 - accuracy: 0.9782\n",
      "Epoch 33/50\n",
      "238/238 [==============================] - 4s 16ms/step - loss: 0.0477 - accuracy: 0.9773\n",
      "Epoch 34/50\n",
      "238/238 [==============================] - 3s 12ms/step - loss: 0.0450 - accuracy: 0.9785\n",
      "Epoch 35/50\n",
      "238/238 [==============================] - 3s 13ms/step - loss: 0.0423 - accuracy: 0.9807\n",
      "Epoch 36/50\n",
      "238/238 [==============================] - 3s 14ms/step - loss: 0.0426 - accuracy: 0.9807\n",
      "Epoch 37/50\n",
      "238/238 [==============================] - 4s 16ms/step - loss: 0.0404 - accuracy: 0.9803\n",
      "Epoch 38/50\n",
      "238/238 [==============================] - 4s 17ms/step - loss: 0.0466 - accuracy: 0.9779\n",
      "Epoch 39/50\n",
      "238/238 [==============================] - 4s 17ms/step - loss: 0.0422 - accuracy: 0.9791\n",
      "Epoch 40/50\n",
      "238/238 [==============================] - 4s 17ms/step - loss: 0.0449 - accuracy: 0.9794\n",
      "Epoch 41/50\n",
      "238/238 [==============================] - 4s 18ms/step - loss: 0.0428 - accuracy: 0.9791\n",
      "Epoch 42/50\n",
      "238/238 [==============================] - 4s 18ms/step - loss: 0.0420 - accuracy: 0.9798\n",
      "Epoch 43/50\n",
      "238/238 [==============================] - 4s 18ms/step - loss: 0.0452 - accuracy: 0.9798\n",
      "Epoch 44/50\n",
      "238/238 [==============================] - 4s 16ms/step - loss: 0.0413 - accuracy: 0.9798\n",
      "Epoch 45/50\n",
      "238/238 [==============================] - 4s 17ms/step - loss: 0.0421 - accuracy: 0.9812\n",
      "Epoch 46/50\n",
      "238/238 [==============================] - 5s 19ms/step - loss: 0.0413 - accuracy: 0.9811\n",
      "Epoch 47/50\n",
      "238/238 [==============================] - 4s 16ms/step - loss: 0.0401 - accuracy: 0.9804\n",
      "Epoch 48/50\n",
      "238/238 [==============================] - 4s 15ms/step - loss: 0.0389 - accuracy: 0.9800\n",
      "Epoch 49/50\n",
      "238/238 [==============================] - 3s 14ms/step - loss: 0.0397 - accuracy: 0.9794\n",
      "Epoch 50/50\n",
      "238/238 [==============================] - 2s 8ms/step - loss: 0.0402 - accuracy: 0.9813\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(x=train_padded,y=train['target'], epochs=50, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mudeli täpsus on 0.9813476800918579\n"
     ]
    }
   ],
   "source": [
    "print(\"Mudeli täpsus on\", hist.history[\"accuracy\"][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Kirjutame tulemused faili'''\n",
    "\n",
    "predictions = pd.DataFrame({'target': (model.predict(test_padded, verbose=0) > 0.5).reshape(-1).astype(int)}, index=test.id)\n",
    "predictions.index.name='id'\n",
    "with open('sample_submission.csv', 'w') as f:\n",
    "    predictions.to_csv(f, line_terminator='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
